{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd875c10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import mode\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import random\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Dropout, Conv2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6d8aaadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = './horizontal/Video-15-47-49-515-31-03-2022/Video-15-47-49-515 (4IIC).mp4'\n",
    "filepath_check = './checkpoint/'\n",
    "input_dim = 500\n",
    "maxCorners = 500\n",
    "frames = 30\n",
    "net_len = 1000\n",
    "units = 100\n",
    "output_size = 2\n",
    "classes_list = [\"stop\", \"move\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d86f99e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal = ['./horizontal/Video-7-36-30-868-22-03-2022/Video-7-36-30-868 (S1WK)',\n",
    "            #'./horizontal/Video-10-6-45-47-30-03-2022/Video-10-6-45-47 (J57V)',\n",
    "            './horizontal/Video-15-43-13-884-22-03-2022/Video-15-43-13-884 (J4NP)',\n",
    "            './horizontal/Video-10-25-45-905-31-03-2022/Video-10-25-45-905 (3W3K)',\n",
    "            './horizontal/Video-10-56-13-801-31-03-2022/Video-10-56-13-801 (X0N9)',            \n",
    "            './horizontal/Video-11-19-18-132-30-03-2022/Video-11-19-18-132 (SH2G)',\n",
    "            './horizontal/Video-12-51-53-673-27-03-2021/Video-12-51-53-673 (NKXJ)',\n",
    "            #'./horizontal/Video-15-26-20-118-29-03-2022/Video-15-26-20-118 (5FLZ)',\n",
    "            './horizontal/Video-15-32-33-709-31-03-2022/Video-15-32-33-709 (7BAA)',\n",
    "            './horizontal/Video-15-41-30-94-29-03-2022/Video-15-41-30-94 (PH33)',\n",
    "            #'./horizontal/Video-15-47-49-515-31-03-2022/Video-15-47-49-515 (4IIC)',\n",
    "            './horizontal/Video-15-49-30-274-29-03-2022/Video-15-49-30-274 (JP92)',\n",
    "            './horizontal/Video-15-8-58-789-27-03-2022/Video-15-8-58-789 (SSQM)',\n",
    "            './horizontal/Video-17-14-15-118-06-03-2021/Video-17-14-15-118 (PE9P)',\n",
    "            './horizontal/Video-17-34-45-652-25-03-2021/Video-17-34-45-652 (BK89)',\n",
    "            './horizontal/Video-17-44-40-74-06-03-2021/Video-17-44-40-74 (CLNF)',\n",
    "            './horizontal/Video-7-51-44-763-22-03-2022/Video-7-51-44-763 (1QN6)',\n",
    "            './horizontal/Video-8-6-54-707-22-03-2022/Video-8-6-54-707 (PKAY)']\n",
    "\n",
    "vertical = ['./vertical/Video-10-15-12-812-14-11-2020/Video-10-15-12-812 (2Y5M)',\n",
    "           './vertical/Video-10-30-21-575-29-09-2021/Video-10-30-21-575 (UOM8)',\n",
    "           './vertical/Video-11-21-2-419-13-09-2021/Video-11-21-2-419 (KVYG)',\n",
    "           './vertical/Video-11-21-6-412-28-12-2020/Video-11-21-6-412 (JQQM)',\n",
    "           './vertical/Video-11-36-12-363-28-09-2021/Video-11-36-12-363 (8119)',\n",
    "           './vertical/Video-11-36-16-421-28-12-2020/Video-11-36-16-421 (PFAQ)',\n",
    "           './vertical/Video-11-5-49-336-13-09-2021/Video-11-5-49-336 (CZPL)',\n",
    "           './vertical/Video-12-23-51-640-02-10-2021/Video-12-23-51-640 (WLWK)',\n",
    "           './vertical/Video-12-39-1-595-02-10-2021/Video-12-39-1-595 (QDUT)',\n",
    "           './vertical/Video-12-44-36-682-24-09-2021/Video-12-44-36-682 (ATO6)',\n",
    "           './vertical/Video-13-16-32-822-10-09-2021/Video-13-16-32-822 (UQ1Q)',\n",
    "           './vertical/Video-13-20-30-695-15-11-2021/Video-13-20-30-695 (VLFO)',\n",
    "           './vertical/Video-13-31-46-773-10-09-2021/Video-13-31-46-773 (MXM7)',\n",
    "           './vertical/Video-16-16-44-458-17-11-2020/Video-16-16-44-458 (LCRL)',\n",
    "           './vertical/Video-16-36-42-174-10-11-2020/Video-16-36-42-174 (IXTE)',\n",
    "           './vertical/Video-16-47-10-870-17-11-2020/Video-16-47-10-870 (YFCN)',\n",
    "           './vertical/Video-17-17-30-919-17-11-2020/Video-17-17-30-919 (ID6X)',\n",
    "           './vertical/Video-17-32-40-752-17-11-2020/Video-17-32-40-752 (E575)',\n",
    "           './vertical/Video-17-47-40-713-02-10-2021/Video-17-47-40-713 (E7IK)',\n",
    "           './vertical/Video-20-21-59-727-24-09-2021/Video-20-21-59-727 (S04R)',\n",
    "           './vertical/Video-20-45-56-152-24-10-2021/Video-20-45-56-152 (6M38)']\n",
    "\n",
    "random.shuffle(horizontal)\n",
    "random.shuffle(vertical)\n",
    "\n",
    "videopath = horizontal# + vertical\n",
    "\n",
    "random.shuffle(videopath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e390c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def six_or_else(a):\n",
    "    if a[1]==6:\n",
    "        return [1,a[2]]\n",
    "    else:\n",
    "        return [0,a[2]]\n",
    "\n",
    "def mode_periods(df):\n",
    "    last_mode = -1\n",
    "    mode_time = []\n",
    "    mode_time.append([1 if df.iloc[0][0] == 6 else 0 , '00:00:00.0000000']) \n",
    "    for row in df.itertuples():  \n",
    "        if row[1] != last_mode:   \n",
    "            mode_time.append(six_or_else(row))\n",
    "        last_mode = row[1]\n",
    "    mode_time.append([1 if df.iloc[-1][0] == 6 else 0 , '1'+df.iloc[-1][1][1:] ] ) \n",
    "    \n",
    "    return mode_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25a63535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(filepath):\n",
    "    df = pd.read_csv(filepath[:-4]+'.csv')[['activityMode','timestamp']]\n",
    "    mode_time = mode_periods(df)\n",
    "    \n",
    "    # Read the video \n",
    "    cap = cv2.VideoCapture(filepath)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 2)\n",
    "    \n",
    "    # Parameters for ShiTomasi corner detection\n",
    "    feature_params = dict(maxCorners = maxCorners,\n",
    "                       qualityLevel = 0.07,\n",
    "                       minDistance = 10,\n",
    "                       blockSize = 5 )\n",
    "\n",
    "    # Parameters for Lucas Kanade optical flow\n",
    "    lk_params = dict(winSize  = (15, 15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "    net = []\n",
    "    label_list = []\n",
    "    i_frame = 0\n",
    "    j_frame = 0\n",
    "    while True:       \n",
    "        ret, old_frame = cap.read()\n",
    "        if not ret:\n",
    "                break\n",
    "        old_frame = cv2.resize(old_frame, (input_dim, input_dim))\n",
    "        height, width, _ = old_frame.shape \n",
    "        part_width = round(width * 0.4)\n",
    "        part_height = round(height * 0.4)\n",
    "        \n",
    "        old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "        cv2.rectangle(old_gray, (part_width, part_height), \n",
    "                          (width - part_width, height - part_height), 0, -1)\n",
    "        # Create a mask image for drawing purposes\n",
    "        mask = np.zeros_like(old_frame)\n",
    "        \n",
    "        while True:\n",
    "            # Read new frame\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            sec = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "            res = datetime.timedelta(seconds = sec/1000)\n",
    "            for i in range(len(mode_time)-1): \n",
    "                if (dt.strptime(mode_time[i][1][:-8], \"%H:%M:%S\") - datetime.datetime(1900, 1, 1) <= res) and\\\n",
    "                    (dt.strptime(mode_time[i+1][1][:-8], \"%H:%M:%S\") - datetime.datetime(1900, 1, 1) >= res):\n",
    "                    label = [mode_time[i][0]]                \n",
    "                    break  \n",
    "                    \n",
    "            if (len(label_list)!=0)and(label == label_list[-1])and(j_frame>maxCorners):\n",
    "                continue \n",
    "                \n",
    "            frame = cv2.resize(frame, (input_dim, input_dim))\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            cv2.rectangle(old_gray, (part_width, part_height), \n",
    "                          (width - part_width, height - part_height), 0, -1)\n",
    "            # Calculate Optical Flow\n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
    "                old_gray, frame_gray, p0, None, **lk_params\n",
    "            )\n",
    "\n",
    "            # Select good points\n",
    "            good_new = p1[st == 1]\n",
    "            good_old = p0[st == 1]\n",
    "            \n",
    "            new_net = good_new - good_old\n",
    "            #print(new_net)\n",
    "            while new_net.shape[0] < maxCorners:                \n",
    "                new_net = np.append(new_net, [[0,0]], axis=0)                  \n",
    "            new_net = np.array(new_net)\n",
    "            new_net[np.lexsort((new_net[:,1],new_net[:,0]))]\n",
    "            \n",
    "            i_frame += 1\n",
    "            \n",
    "            if True:#(len(label_list)==0):\n",
    "                j_frame += 1\n",
    "                net.append(new_net) \n",
    "                label_list.append(label)\n",
    "                # Update the previous frame and previous points\n",
    "                old_gray = frame_gray.copy()\n",
    "                p0 = good_new.reshape(-1, 1, 2)\n",
    "                \n",
    "                #if j_frame >= 100:\n",
    "                   # break\n",
    "                continue\n",
    "            \n",
    "            if ((label == label_list[-1]) and (j_frame<=frames)):\n",
    "                j_frame += 1\n",
    "                net.append(new_net) \n",
    "                label_list.append(label)\n",
    "                # Update the previous frame and previous points\n",
    "                old_gray = frame_gray.copy()\n",
    "                p0 = good_new.reshape(-1, 1, 2)\n",
    "                if j_frame >= frames:\n",
    "                    break\n",
    "                continue           \n",
    "                        \n",
    "            if (label != label_list[-1]):\n",
    "                j_frame = 0\n",
    "                net.append(new_net) \n",
    "                label_list.append(label)\n",
    "                # Update the previous frame and previous points\n",
    "                old_gray = frame_gray.copy()\n",
    "                p0 = good_new.reshape(-1, 1, 2)\n",
    "                break\n",
    "                \n",
    "    return np.array(net)/input_dim, np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14cccd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_full(filepath):\n",
    "    df = pd.read_csv(filepath[:-4]+'.csv')[['activityMode','timestamp']]\n",
    "    mode_time = mode_periods(df)\n",
    "    \n",
    "    # Read the video \n",
    "    cap = cv2.VideoCapture(filepath)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 2)\n",
    "    \n",
    "    # Parameters for ShiTomasi corner detection\n",
    "    feature_params = dict(maxCorners = maxCorners,\n",
    "                       qualityLevel = 0.07,\n",
    "                       minDistance = 10,\n",
    "                       blockSize = 5 )\n",
    "\n",
    "    # Parameters for Lucas Kanade optical flow\n",
    "    lk_params = dict(winSize  = (15, 15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "    net = []\n",
    "    label_list = []\n",
    "    while True:       \n",
    "        ret, old_frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "                break\n",
    "                \n",
    "        old_frame = cv2.resize(old_frame, (input_dim, input_dim))\n",
    "        height, width, _ = old_frame.shape \n",
    "        part_width = round(width * 0.4)\n",
    "        part_height = round(height * 0.4)\n",
    "        \n",
    "        old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "        #cv2.rectangle(old_gray, (part_width, part_height), \n",
    "                          #(width - part_width, height - part_height), 0, -1)\n",
    "        # Create a mask image for drawing purposes\n",
    "        mask = np.zeros_like(old_frame)\n",
    "        \n",
    "        while True:\n",
    "            # Read new frame\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            sec = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "            res = datetime.timedelta(seconds = sec/1000)\n",
    "            for i in range(len(mode_time)-1): \n",
    "                if (dt.strptime(mode_time[i][1][:-8], \"%H:%M:%S\") - datetime.datetime(1900, 1, 1) <= res) and\\\n",
    "                    (dt.strptime(mode_time[i+1][1][:-8], \"%H:%M:%S\") - datetime.datetime(1900, 1, 1) >= res):\n",
    "                    label = [mode_time[i][0]]                \n",
    "                    break                    \n",
    "                \n",
    "            frame = cv2.resize(frame, (input_dim, input_dim))\n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            #cv2.rectangle(old_gray, (part_width, part_height), \n",
    "                          #(width - part_width, height - part_height), 0, -1)\n",
    "            # Calculate Optical Flow\n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
    "                old_gray, frame_gray, p0, None, **lk_params\n",
    "            )\n",
    "            if p1 is None:\n",
    "                break\n",
    "            # Select good points\n",
    "            good_new = p1[st == 1]\n",
    "            good_old = p0[st == 1]\n",
    "            \n",
    "            new_net = good_new - good_old\n",
    "            \n",
    "            while new_net.shape[0] < maxCorners:                \n",
    "                new_net = np.append(new_net, [[-999999,-999999]], axis=0) \n",
    "            #new_net = [[x[0] + input_dim,x[1] + input_dim] for x in new_net]\n",
    "            new_net = np.array(new_net)/(input_dim)\n",
    "            new_net[np.lexsort((new_net[:,1],new_net[:,0]))]\n",
    "            \n",
    "\n",
    "            old_gray = frame_gray.copy()\n",
    "            p0 = good_new.reshape(-1, 1, 2)\n",
    "            \n",
    "            net.append(new_net)\n",
    "            label_list.append(label)\n",
    "                \n",
    "    return np.array(net), np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2217823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_full_2(video_path):    \n",
    "    # Read the video \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 2)\n",
    "    \n",
    "    # Parameters for ShiTomasi corner detection\n",
    "    feature_params = dict(maxCorners = maxCorners,\n",
    "                       qualityLevel = 0.07,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "    # Parameters for Lucas Kanade optical flow\n",
    "    lk_params = dict(winSize  = (15, 15),\n",
    "                  maxLevel = 3,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "    net_all = []\n",
    "    label_list_all = []\n",
    "    median_all = []\n",
    "    x_y_median = []\n",
    "    # Create random colors\n",
    "    while True:       \n",
    "        # Take first frame and find corners in it\n",
    "        ret, old_frame = cap.read()\n",
    "        old_frame = cv2.resize(old_frame, (input_dim, input_dim))\n",
    "        height, width, _ = old_frame.shape \n",
    "        part_width = round(width * 0.3)\n",
    "        part_height = round(height * 0.3)\n",
    "        \n",
    "        old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #cv2.rectangle(old_gray, (part_width, part_height), \n",
    "                          #(width - part_width, height - part_height), 0, -1)\n",
    "        \n",
    "        p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "\n",
    "        # Create a mask image for drawing purposes\n",
    "        mask = np.zeros_like(old_frame)\n",
    "        net = []\n",
    "        label_list = []\n",
    "        median_list = []\n",
    "        while True:\n",
    "            # Read new frame\n",
    "            ret, frame = cap.read()            \n",
    "            if not ret:\n",
    "                return np.array(net_all), np.array(label_list_all)\n",
    "            frame = cv2.resize(frame, (input_dim, input_dim))\n",
    "            #cv2.rectangle(frame, (part_width, part_height), \n",
    "                          #(width - part_width, height - part_height), 0, -1)\n",
    "            \n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            # Calculate Optical Flow\n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
    "                old_gray, frame_gray, p0, None, **lk_params\n",
    "            )\n",
    "            if p1 is None:\n",
    "                continue\n",
    "\n",
    "            # Select good points\n",
    "            good_new = p1[st == 1]\n",
    "            good_old = p0[st == 1]\n",
    "            \n",
    "            new_net = good_new - good_old\n",
    "            \n",
    "            #print(new_net)\n",
    "            \n",
    "            while new_net.shape[0] < maxCorners:                \n",
    "                new_net = np.append(new_net, [[-999999,-999999]], axis=0)                  \n",
    "            new_net = np.array(new_net)\n",
    "            new_net[np.lexsort((new_net[:,1],new_net[:,0]))]   \n",
    "            net.append(new_net)  \n",
    "            \n",
    "            median_frame = np.median(np.absolute(new_net))  \n",
    "            median_list.append(median_frame) \n",
    "\n",
    "            # Update the previous frame and previous points\n",
    "            old_gray = frame_gray.copy()\n",
    "            p0 = good_new.reshape(-1, 1, 2)\n",
    "            \n",
    "            if np.array(net).shape[0] >= frames:\n",
    "                \n",
    "                net = np.array(net) / input_dim                \n",
    "                median = np.median(median_list) \n",
    "                if median >= 0.1:\n",
    "                    median_class_name = 1\n",
    "                else:\n",
    "                    median_class_name = 0\n",
    "                    \n",
    "                for i in range(len(net)):\n",
    "                    label_list.append([median_class_name])\n",
    "                    \n",
    "                if len(net_all) == 0:\n",
    "                    net_all = net\n",
    "                    label_list_all = label_list\n",
    "                else:\n",
    "                    net_all = np.concatenate((net_all, net), 0)\n",
    "                    label_list_all = np.concatenate((label_list_all, label_list), 0)\n",
    "                \n",
    "                break\n",
    "                \n",
    "    return np.array(net_all), np.array(label_list_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d01d61f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lucas_kanade_method_orig(video_path, callbacks):\n",
    "    df = pd.read_csv(video_path[:-4]+'.csv')[['activityMode','timestamp']]\n",
    "    mode_time = mode_periods(df)\n",
    "    \n",
    "    model = get_CNN(units, input_dim, output_size)\n",
    "    \n",
    "    model.compile(\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=\"sgd\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    # Read the video \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 2)\n",
    "    \n",
    "    # Parameters for ShiTomasi corner detection\n",
    "    feature_params = dict(maxCorners = maxCorners,\n",
    "                       qualityLevel = 0.07,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "    # Parameters for Lucas Kanade optical flow\n",
    "    lk_params = dict(winSize  = (15, 15),\n",
    "                  maxLevel = 3,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "    # Create random colors\n",
    "    color = np.random.randint(0, 255, (500, 3))\n",
    "    predicted_class_name = ' '\n",
    "    median_class_name = ' '\n",
    "    while True:       \n",
    "        start = time.time()\n",
    "        # Take first frame and find corners in it\n",
    "        ret, old_frame = cap.read()\n",
    "        old_frame = cv2.resize(old_frame, (input_dim, input_dim))\n",
    "        height, width, _ = old_frame.shape \n",
    "        part_width = round(width * 0.3)\n",
    "        part_height = round(height * 0.3)\n",
    "        \n",
    "        old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #cv2.rectangle(old_gray, (part_width, part_height), \n",
    "                          #(width - part_width, height - part_height), 0, -1)\n",
    "        \n",
    "        p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "\n",
    "        # Create a mask image for drawing purposes\n",
    "        mask = np.zeros_like(old_frame)\n",
    "        \n",
    "        net = []\n",
    "        label_list = []\n",
    "        median_list = []\n",
    "        while True:\n",
    "            # Read new frame\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, (input_dim, input_dim))\n",
    "            #cv2.rectangle(frame, (part_width, part_height), \n",
    "                          #(width - part_width, height - part_height), 0, -1)\n",
    "            \n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            # Calculate Optical Flow\n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
    "                old_gray, frame_gray, p0, None, **lk_params\n",
    "            )\n",
    "            if p1 is None:\n",
    "                break\n",
    "\n",
    "            # Select good points\n",
    "            good_new = p1[st == 1]\n",
    "            good_old = p0[st == 1]\n",
    "            \n",
    "            new_net_orig = good_new - good_old\n",
    "            new_net = new_net_orig\n",
    "            #print(new_net)\n",
    "            \n",
    "            while new_net.shape[0] < maxCorners:                \n",
    "                new_net = np.append(new_net, [[-999999,-999999]], axis=0)                  \n",
    "            new_net = np.array(new_net)\n",
    "            new_net[np.lexsort((new_net[:,1],new_net[:,0]))]   \n",
    "            net.append(new_net)\n",
    "            \n",
    "            # Draw the tracks\n",
    "            for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "                a, b = new.ravel()\n",
    "                c, d = old.ravel()\n",
    "                mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n",
    "                #frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
    " \n",
    "            mask_med = np.zeros_like(old_frame)\n",
    "            median_frame = np.median(np.absolute(new_net_orig))  \n",
    "            median_list.append(median_frame)\n",
    "            \n",
    "            median_frame_x = input_dim/2 + np.median(new_net_orig[:, 0])*80  \n",
    "            median_frame_y = input_dim/2 + np.median(new_net_orig[:, 1])*80\n",
    "            mask_med = cv2.line(mask_med, (int(input_dim/2), int(input_dim/2)),\n",
    "                                (int(median_frame_x), int(median_frame_y)), (0, 0, 255), 3)\n",
    "                        \n",
    "            # Display the demo\n",
    "            img = cv2.add(frame, mask_med)\n",
    "            #img = cv2.add(img, mask_med)\n",
    "            \n",
    "            cv2.putText(img, predicted_class_name, \n",
    "                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            cv2.putText(img, median_class_name, \n",
    "                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(img, str(median_frame), \n",
    "                        (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.imshow(\"frame\", img)\n",
    "            k = cv2.waitKey(25) & 0xFF\n",
    "            if k == 27:\n",
    "                break\n",
    "\n",
    "            # Update the previous frame and previous points\n",
    "            old_gray = frame_gray.copy()\n",
    "            p0 = good_new.reshape(-1, 1, 2)\n",
    "            if np.array(net).shape[0] >= frames:\n",
    "                net = np.array(net) / input_dim\n",
    "                #history = model.fit(\n",
    "                    #net, np.array(label_list), batch_size=20, epochs=1,\n",
    "                    #callbacks=callbacks,\n",
    "                    #validation_data  = (val_x, val_y) \n",
    "                #)\n",
    "                predicted_labels_probabilities = model.predict(net)\n",
    "                summa = predicted_labels_probabilities[0]\n",
    "                #print(predicted_labels_probabilities)\n",
    "                for i in range(1, len(predicted_labels_probabilities)):\n",
    "                    summa += predicted_labels_probabilities[i]\n",
    "                #print(model.predict(net))\n",
    "                predicted_label = np.argmax(summa)\n",
    "        \n",
    "                # Accessing The Class Name using predicted label.\n",
    "                predicted_class_name = classes_list[predicted_label]\n",
    "                \n",
    "                median = np.median(median_list) \n",
    "                if median >= 0.1:\n",
    "                    median_class_name = classes_list[1]\n",
    "                else:\n",
    "                    median_class_name = classes_list[0]\n",
    "                \n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3de11118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lucas_kanade_method_orig_2(video_path, callbacks):\n",
    "    \n",
    "    model = get_CNN(units, input_dim, output_size)\n",
    "    \n",
    "    model.compile(\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        optimizer=\"sgd\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    # Read the video \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 2)\n",
    "    \n",
    "    # Parameters for ShiTomasi corner detection\n",
    "    feature_params = dict(maxCorners = maxCorners,\n",
    "                       qualityLevel = 0.07,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "    # Parameters for Lucas Kanade optical flow\n",
    "    lk_params = dict(winSize  = (15, 15),\n",
    "                  maxLevel = 3,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "    # Create random colors\n",
    "    color = np.random.randint(0, 255, (500, 3))\n",
    "    predicted_class_name = ' '\n",
    "    median_class_name = ' '\n",
    "    while True:       \n",
    "        # Take first frame and find corners in it\n",
    "        ret, old_frame = cap.read()\n",
    "        if not ret:\n",
    "                break\n",
    "        old_frame = cv2.resize(old_frame, (input_dim, input_dim))\n",
    "        height, width, _ = old_frame.shape \n",
    "        part_width = round(width * 0.3)\n",
    "        part_height = round(height * 0.3)\n",
    "        \n",
    "        old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #cv2.rectangle(old_gray, (part_width, part_height), \n",
    "                          #(width - part_width, height - part_height), 0, -1)\n",
    "        \n",
    "        p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "\n",
    "        # Create a mask image for drawing purposes\n",
    "        mask = np.zeros_like(old_frame)\n",
    "        \n",
    "        net = []\n",
    "        label_list = []\n",
    "        median_list = []\n",
    "        median_list_l = []\n",
    "        median_list_r = []\n",
    "        while True:\n",
    "            # Read new frame\n",
    "            ret, frame = cap.read()\n",
    "            \n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, (input_dim, input_dim))\n",
    "            #cv2.rectangle(frame, (part_width, part_height), \n",
    "                          #(width - part_width, height - part_height), 0, -1)\n",
    "            \n",
    "            frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            # Calculate Optical Flow\n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
    "                old_gray, frame_gray, p0, None, **lk_params\n",
    "            )\n",
    "            if p1 is None:\n",
    "                break\n",
    "\n",
    "            # Select good points\n",
    "            good_new = p1[st == 1]\n",
    "            good_old = p0[st == 1]\n",
    "            \n",
    "            new_net_orig = good_new - good_old\n",
    "            new_net = new_net_orig\n",
    "            \n",
    "            new_net_l = np.array([])\n",
    "            new_net_r = np.array([])\n",
    "            for i in range(len(good_new)):\n",
    "                if good_new[i][0] < input_dim/2:\n",
    "                    if len(new_net_l) == 0:\n",
    "                        new_net_l = np.array([good_new[i] - good_old[i]])\n",
    "                    else:\n",
    "                        new_net_l = np.append(new_net_l, [good_new[i] - good_old[i]], axis=0)\n",
    "                else:\n",
    "                    if len(new_net_r) == 0:\n",
    "                        new_net_r = np.array([good_new[i] - good_old[i]])\n",
    "                    else:\n",
    "                        new_net_r = np.append(new_net_r, [good_new[i] - good_old[i]], axis=0)\n",
    "            #print(new_net_l.shape, new_net_orig.shape)\n",
    "            while new_net.shape[0] < maxCorners:                \n",
    "                new_net = np.append(new_net, [[-999999,-999999]], axis=0)                  \n",
    "            new_net = np.array(new_net)\n",
    "            new_net[np.lexsort((new_net[:,1],new_net[:,0]))]   \n",
    "            net.append(new_net)\n",
    "            \n",
    "            # Draw the tracks\n",
    "            for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "                a, b = new.ravel()\n",
    "                c, d = old.ravel()\n",
    "                mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n",
    "                #frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
    " \n",
    "            mask_med = np.zeros_like(old_frame)\n",
    "    \n",
    "            median_frame = np.median(np.absolute(new_net_orig))  \n",
    "            median_list.append(median_frame)\n",
    "            \n",
    "            median_frame_x_l = input_dim/4 + np.median(new_net_l[:, 0])*80  \n",
    "            median_frame_y_l = input_dim/2 + np.median(new_net_l[:, 1])*80\n",
    "            mask_med = cv2.line(mask_med, (int(input_dim/4), int(input_dim/2)),\n",
    "                                (int(median_frame_x_l), int(median_frame_y_l)), (0, 0, 255), 3)\n",
    "            \n",
    "            median_frame_x_r = 3*input_dim/4 + np.median(new_net_r[:, 0])*80  \n",
    "            median_frame_y_r = input_dim/2 + np.median(new_net_r[:, 1])*80\n",
    "            mask_med = cv2.line(mask_med, (int(3*input_dim/4), int(input_dim/2)),\n",
    "                                (int(median_frame_x_r), int(median_frame_y_r)), (0, 0, 255), 3)\n",
    "            \n",
    "            median_frame_l = np.median(np.absolute(new_net_l))\n",
    "            median_list_l.append(median_frame_l)\n",
    "            \n",
    "            median_frame_r = np.median(np.absolute(new_net_r))\n",
    "            median_list_r.append(median_frame_r)\n",
    "            \n",
    "            img = cv2.add(frame, mask_med)\n",
    "            #img = cv2.add(img, mask_med)\n",
    "            \n",
    "            cv2.putText(img, predicted_class_name, \n",
    "                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.putText(img, median_class_name, \n",
    "                        (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(img, str(median_frame), \n",
    "                        (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            cv2.putText(img, str(median_frame_l), \n",
    "                        (30, 300), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.putText(img, str(median_frame_r), \n",
    "                        (300, 300), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            \n",
    "            cv2.imshow(\"frame\", img)\n",
    "            k = cv2.waitKey(25) & 0xFF\n",
    "            if k == 27:\n",
    "                break\n",
    "\n",
    "            # Update the previous frame and previous points\n",
    "            old_gray = frame_gray.copy()\n",
    "            p0 = good_new.reshape(-1, 1, 2)\n",
    "            if np.array(net).shape[0] >= frames:\n",
    "                net = np.array(net) / input_dim\n",
    "                #history = model.fit(\n",
    "                    #net, np.array(label_list), batch_size=20, epochs=1,\n",
    "                    #callbacks=callbacks,\n",
    "                    #validation_data  = (val_x, val_y) \n",
    "                #)\n",
    "                predicted_labels_probabilities = model.predict(net)\n",
    "                summa = predicted_labels_probabilities[0]\n",
    "                #print(predicted_labels_probabilities)\n",
    "                for i in range(1, len(predicted_labels_probabilities)):\n",
    "                    summa += predicted_labels_probabilities[i]\n",
    "                #print(model.predict(net))\n",
    "                predicted_label = np.argmax(summa)\n",
    "        \n",
    "                # Accessing The Class Name using predicted label.\n",
    "                predicted_class_name = classes_list[predicted_label]\n",
    "                \n",
    "                median_l = np.median(median_list_l) \n",
    "                if median_l >= 0.08:\n",
    "                    median_class_name_l = 1\n",
    "                else:\n",
    "                    median_class_name_l = 0\n",
    "                                                    \n",
    "                median_r = np.median(median_list_r) \n",
    "                if median_r >= 0.08:\n",
    "                    median_class_name_r = 1\n",
    "                else:\n",
    "                    median_class_name_r = 0\n",
    "                    \n",
    "                if median_class_name_r == 1 and median_class_name_l == 1:\n",
    "                    median_class_name = classes_list[1]\n",
    "                else:\n",
    "                    median_class_name = classes_list[0]\n",
    "                \n",
    "                \n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "44c929c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [163]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlucas_kanade_method_orig_2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./horizontal/Video-15-47-49-515-31-03-2022/Video-15-47-49-515 (4IIC).mp4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [162]\u001b[0m, in \u001b[0;36mlucas_kanade_method_orig_2\u001b[0;34m(video_path, callbacks)\u001b[0m\n\u001b[1;32m    142\u001b[0m cv2\u001b[38;5;241m.\u001b[39mputText(img, \u001b[38;5;28mstr\u001b[39m(median_frame_r), \n\u001b[1;32m    143\u001b[0m             (\u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m300\u001b[39m), cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    145\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe\u001b[39m\u001b[38;5;124m\"\u001b[39m, img)\n\u001b[0;32m--> 146\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lucas_kanade_method_orig_2('./horizontal/Video-15-47-49-515-31-03-2022/Video-15-47-49-515 (4IIC).mp4',\n",
    "                         callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e8c233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RNN(units, input_dim, output_size):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.LSTM(units, return_sequences=True, input_shape=(None, 2)))\n",
    "    model.add(layers.GRU(64))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Dense(32, activation=\"relu\"))\n",
    "    model.add(layers.Dense(output_size))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a645f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CNN(units, input_dim, output_size): \n",
    "    model = keras.Sequential()\n",
    "    #model.add(Conv2D(2, (2, 2), input_shape=(100, 2, 1)))\n",
    "    model.add(Input((maxCorners,2)))\n",
    "    model.add(Flatten())  \n",
    "    #model.add(Dense(500, activation='relu')) \n",
    "    #model.add(Dropout(0.4))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Dense(250, activation='relu'))\n",
    "    #model.add(Dropout(0.4))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Dense(100, activation='relu'))\n",
    "    #model.add(Dropout(0.4))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(55, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a940d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25680, 100, 2) (25680, 1)\n"
     ]
    }
   ],
   "source": [
    "val_x, val_y = data_full_2('./horizontal/Video-15-47-49-515-31-03-2022/Video-15-47-49-515 (4IIC).mp4')\n",
    "print(val_x.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e1d3329",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath_check, monitor=\"val_accuracy\",\n",
    "        save_best_only=True, verbose=1,\n",
    "        mode='max')\n",
    "callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37f43162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-16 15:24:41.352091: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-05-16 15:24:41.352146: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (alexander-HP-Pavilion-Gaming-Laptop-15-cx0xxx): /proc/driver/nvidia/version does not exist\n",
      "2022-05-16 15:24:41.352858: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Adding Early Stopping Callback\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_accuracy', patience = 15,\n",
    "                                        mode = 'max', restore_best_weights = True)\n",
    "\n",
    "model = get_CNN(units, input_dim, output_size)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4f699bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data_full_2('./horizontal/Video-15-26-20-118-29-03-2022/Video-15-26-20-118 (5FLZ).mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31c5961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2, y2 = data_full_2('./horizontal/Video-15-47-49-515-31-03-2022/Video-15-47-49-515 (4IIC).mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86cb7848",
   "metadata": {},
   "outputs": [],
   "source": [
    "x3, y3 = data_full_2('./horizontal/Video-15-41-30-94-29-03-2022/Video-15-41-30-94 (PH33).mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97c8a1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x4, y4 = data_full_2('./vertical/Video-11-5-49-336-13-09-2021/Video-11-5-49-336 (CZPL).mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad28b12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.concatenate((x, x2), 0)\n",
    "yy = np.concatenate((y, y2), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dc78129",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.concatenate((xx, x3), 0)\n",
    "yy = np.concatenate((yy, y3), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef393342",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.concatenate((xx, x4), 0)\n",
    "yy = np.concatenate((yy, y4), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e6046c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "            xx, yy, batch_size=20, epochs=15,\n",
    "            callbacks = callbacks,\n",
    "            validation_data  = (val_x, val_y),\n",
    "            shuffle = True\n",
    "    \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a33af2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in videopath:        \n",
    "    x, y = data_full(i + '.mp4')   \n",
    "      \n",
    "    model.fit(\n",
    "            np.array(x), np.array(y), batch_size=20, epochs=3,\n",
    "            callbacks = callbacks,\n",
    "            validation_data  = (val_x, val_y),\n",
    "            shuffle = True \n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
